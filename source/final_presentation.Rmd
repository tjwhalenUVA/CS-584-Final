---
title: "Voice Recognition"
output: 
  flexdashboard::flex_dashboard:
    orientation: columns
    vertical_layout: fill
css: style.css
---

```{r setup, include=FALSE}
library(flexdashboard)
source('_Packages.R')
source('_Data.R')
source('_EDA.R')
source('_ModelResults.R')
```

Home
=====================================

## Column
<h1><b><center>Gender Classification via Voice</center></b></h1>
<h3><b><center>Jake Whalen</center></b></h3>
<h5><b><center>CS 584 Final Project</center></b></h5>
<h5><b><center>Fall 2017</center></b></h5>
<b><center>[Start](#summary)</center></b>

Summary
=====================================
## Column
### 
<font size="5"><b>Choosing a Project</b></font>
<font size="3">
<ul>
  <li>Topic? Sports, Beer, Other </li>
  <li>Supervised or unsupervised learning?</li>
  <li>Data Source: Download, Web Scrape, Social Media</li>
  <li>Tools: Python, R, Weka, Tableau, Excel</li>
</ul>
</font>
<br>
<font size="5"><b>Choice</b></font>
<font size="3">
<ul>
  <li>Data from Kaggle</li>
  <li>Audio Analysis</li>
  <li>Supervised Learning</li>
  <li>Classification</li>
  <li>ML in Python</li>
  <li>Presentation & Report in R Markdown</li>
  <li>Excel for results transfer</li>
</ul>
</font>
<br>
<font size="5"><b>Goals</b></font>
<font size="3">
<ul>
  <li>Classify audio clip subjects gender</li>
  <li>Learn what features best seperate gender in audio</li>
  <li>Look for other potential clusters within the data</li>
</ul>
</font>

Method
=====================================

## Column

### <b>Exploration</b>
<ol>
  <li>Read the data into R/Python</li>
  <li>Ran summary functions on features</li>
  <li>Plotted the data</li>
  <li>Look for patterns and relationships between features</li>
  <li>Determine what features seperate genders best</li>
</ol>

###
```{r}
ggplotly(scatterSample) %>%
  layout(showlegend = FALSE) %>% 
  config(displayModeBar = F)
```

## Column

### <b>Classification</b>
<ol>
  <li>Used Scikit-learn in Python</li>
  <li>Split the data for training/testing (2/3, 1/3)</li>
  <li>Used gridsearch to identify the best parameters</li>
  <li>KNN (K-Nearest Neighbors)</li>
  <li>Decision Tree (DT)</li>
  <li>Suport Vector Machine (SVM)</li>
  <li>Logistic Regression (Log R)</li>
  <li>Observed prediction outcomes. Could do better.</li>
  <li>Attempt to Improve on initial results</li>
  <li>KNN: Transform data with PCA</li>
  <li>Decision Tree: Use multiple trees with Random Forest</li>
  <li>SVM: Transform data with PCA</li>
  <li>Log R: Normalized data from 0 to 1 in each feature</li>
</ol>

###
<img src="C:/Users/e481340/Documents/GMU MASTERS/CS 584/CS584_Final/data/machine-learning.jpg" alt="Machine Learning">

## Column

### <b>Review</b>
<ul>
  <li>Confusion Matrix</li>
  <li>Overall Accuracy Scores</li>
  <li>Male Accuracy</li>
  <li>Female Accuracy</li>
  <li>ROC & AUC</li>
  <li>Parameter Influence</li>
  <li>Fit & Score Times</li>
</ul>

###
```{r}
ggplotly(knn_cm) %>%
  layout(showlegend = FALSE) %>% 
  config(displayModeBar = F)
```

Overview {data-navmenu="Data"}
=====================================

## Column {.tabset}

### Description
<font size="5"><b>Dataset Comments</b></font>
<font size="3">
<ul>
  <li>Database created to identify a voice as male or female, based upon acoustic properties of the voice and speech.</li>
  <li>The dataset consists of 3,168 recorded voice samples, collected from male and female speakers.</li>
  <li>The voice samples are pre-processed by acoustic analysis in R using the seewave and tuneR packages, with an analyzed frequency range of 0hz-280hz (human vocal range).</li>
  <li>The samples are represented by 21 different features</li>
  <li>Source: <a href="https://www.kaggle.com/primaryobjects/voicegender" target="_blank">Voice Gender Data</a></li>
</ul>
</font>

### Definitions
```{r definitionsTable}
definitions %>%
  datatable(., 
            rownames=F, 
            options = list(paging=F, 
                           dom = 't'))
```


### Sample

```{r sampleView}
voice %>%
  head(., n=20) %>%
  datatable(., 
            rownames=F, 
            options = list(paging=F, 
                           dom = 't'))
```

EDA {data-navmenu="Data"}
=====================================

## Column {.tabset}

### Classes
```{r}
genderCount
```


### Distributions

```{r Distributions}
allDensity
```

### Boxplots

```{r}
allBoxPlot
```


### T Test
```{r}
tTestDT
```


### Heatmap

```{r summary}
ggheatmap
```

### Scatter Plot

```{r Scatterplot}
oneVall
```

### 3D Plot

```{r 3D}
p
```


KNN {data-navmenu="Methods"}
=====================================

## Column

<h4><b><center>K-Nearest Neighbors</center></b></h4>

###
<b>Summary</b>
<ul>
  <li>Used untransformed data</li>
  <li>Better then a dumb classifier (50/50)</li>
  <li>Distance weights outperformed Uniform weights</li>
  <li><b>P:</b> Manhattan Distance produced better CV results (p=1)</li>
  <li><b>Algorithm:</b> auto attempts to decide the most appropriate algorithm based on values </li>
  <li><b>Weights:</b> distance weights points by the inverse of their distance. in this case, closer neighbors of a query point will have a greater influence than neighbors which are further away</li>
</ul>

<b>Best Parameters</b>
<ul>
  <li>`r best_params(knn)`</li>
</ul>

###
```{r}
ggplotly(knn_cm) %>%
  layout(showlegend = FALSE) %>% 
  config(displayModeBar = F)
```

## Column

###
```{r}
ggplotly(knn_score.graph) %>% 
  config(displayModeBar = F)
```

###
```{r}
knn_result_dt
```



Decision Tree {data-navmenu="Methods"}
=====================================

## Column

<h4><b><center>Decision Tree</center></b></h4>

###
<b>Summary</b>
<ul>
  <li>Used untransformed data</li>
  <li>MeanFun, sp.ent & IQR account for +90% of feature importance</li>
  <li><b>Presort:</b> presort the data to speed up the finding of best splits in fitting</li>
  <li><b>Splitter:</b> The strategy used to choose the split at each node</li>
  <li>Better at identifying males</li>
  <li>Easiest model to interpret (follow the branches)</li>
  <li>[Tree](https://github.com/tjwhalenUVA/CS-584-Final/blob/master/Trees/dt.pdf)</li>
</ul>

<b>Best Parameters</b>
<ul>
  <li>`r best_params(dt)`</li>
</ul>



###
```{r}
ggplotly(dt_cm) %>%
  layout(showlegend = FALSE) %>% 
  config(displayModeBar = F)
```

## Column

###
```{r}
ggplotly(dt_feature.graph) %>%
  layout(showlegend = FALSE) %>% 
  config(displayModeBar = F)
```

###
```{r}
dt_result_dt
```

SVM {data-navmenu="Methods"}
=====================================
## Column

<h4><b><center>Support Vector Machine</center></b></h4>

###
<b>Summary</b>
<ul>
  <li>Modified penalty parameter to acheive better results</li>
  <li>Higher penalties acheived better scores</li>
  <li>Better at classifying males</li>
</ul>

<b>Best Parameters</b>
<ul>
  <li>`r best_params(svm)`</li>
</ul>

###
```{r}
ggplotly(svm_cm) %>%
  layout(showlegend = FALSE) %>% 
  config(displayModeBar = F)
```

## Column

###
```{r}
ggplotly(svm_result.graph) %>%
  config(displayModeBar = F)
```

###
```{r}
svm_result_dt
```

Log Reg {data-navmenu="Methods"}
=====================================
## Column

<h4><b><center>Logistic Regression</center></b></h4>

###
<b>Summary</b>
<ul>
  <li>Untransformed data</li>
  <li>Best Male accuracy</li>
  <li>Outperformed Log Reg (Normal)</li>
  <li><b>C:</b> Inverse of regularization strength</li>
  <li><b>fit_intercept:</b> Specifies if a constant (a.k.a. bias or intercept) should be added to the decision function</li>
  <li><b>penalty:</b> Used to specify the norm used in the penalization</li>
</ul>

<b>Best Parameters</b>
<ul>
  <li>`r best_params(lr)`</li>
</ul>

###
```{r}
ggplotly(lr_cm) %>%
  layout(showlegend = FALSE) %>% 
  config(displayModeBar = F)
```

## Column

###
```{r}
ggplotly(lr_result.graph) %>%
  layout(showlegend = FALSE) %>% 
  config(displayModeBar = F)
```

###
```{r}
lr_result_dt
```

Random Forest {data-navmenu="Methods"}
=====================================

## Column

<h4><b><center>Random Forest</center></b></h4>

###
<b>Summary</b>
<ul>
  <li>Best Female accuracy</li>
  <li>Took longer to fit then Decision Tree</li>
</ul>

<b>Best Parameters</b>
<ul>
  <li>`r best_params(rf)`</li>
</ul>

###
```{r}
ggplotly(rf_cm) %>%
  layout(showlegend = FALSE) %>% 
  config(displayModeBar = F)
```

## Column

###
```{r}
ggplotly(rf_result.graph) %>%
  layout(showlegend = FALSE) %>% 
  config(displayModeBar = F)
```

###
```{r}
rf_result_dt
```

KNN (PCA) {data-navmenu="Methods"}
=====================================
## Column

<h4><b><center>K-Nearest Neighbors (PCA)</center></b></h4>

###
<b>Summary</b>
<ul>
  <li>Best overall accuracy</li>
  <li>9 PCA components used</li>
  <li>The fewer the neighbors the better</li>
</ul>

<b>Best Parameters</b>
<ul>
  <li>`r best_params(knn.pca)`</li>
</ul>

###
```{r}
ggplotly(knn.pca_cm) %>%
  layout(showlegend = FALSE) %>% 
  config(displayModeBar = F)
```

## Column

###
```{r}
ggplotly(knn.pca_score.graph) %>%
  config(displayModeBar = F)
```

###
```{r}
knn.pca_result_dt
```

SVM (PCA) {data-navmenu="Methods"}
=====================================
## Column

<h4><b><center>Support Vector Machine (PCA)</center></b></h4>

###
<b>Summary</b>
<ul>
  <li>Improvement over SVM on untransformed data</li>
  <li>Adjusted penalty parameter C of the error term</li>
  <li>Acheived best performance at much lower penalty parameter levels</li>
</ul>

<b>Best Parameters</b>
<ul>
  <li>`r best_params(svm.pca)`</li>
</ul>

###
```{r}
ggplotly(svm.pca_cm) %>%
  layout(showlegend = FALSE) %>% 
  config(displayModeBar = F)
```

## Column

###
```{r}
ggplotly(svm.pca_result.graph) %>%
  config(displayModeBar = F)
```

###
```{r}
svm.pca_result_dt
```

Log Reg (Normal) {data-navmenu="Methods"}
=====================================
## Column

<h4><b><center>Logistic Regression (Normalized)</center></b></h4>

###
<b>Summary</b>
<ul>
  <li>Performed worse then Log Regression on untransformed data</li>
  <li>Decrease in performance due to decrease in Male accuracy</li>
  <li>Slight improvement in Female accuracy compared to first Log R</li>
</ul>

<b>Best Parameters</b>
<ul>
  <li>`r best_params(lr.norm)`</li>
</ul>

###
```{r}
ggplotly(lr.norm_cm) %>%
  layout(showlegend = FALSE) %>% 
  config(displayModeBar = F)
```

## Column

###
```{r}
ggplotly(lr.norm_result.graph) %>%
  layout(showlegend = FALSE) %>% 
  config(displayModeBar = F)
```

###
```{r}
lr.norm_result_dt
```


Conclusions {.storyboard}
=====================================

### <font size="5"><b>Criteria</b></font>
```{r}
ggplotly(model_criteria) %>%
  config(displayModeBar = F)
```

***
<b>Accuracy</b>
<ol>
  <li>KNN (PCA)</li>
  <li>Random Forest</li>
  <li>Log Regression</li>
</ol>

<b>Male Accuracy</b>
<ol>
  <li>Log Regression</li>
  <li>Log Regression (Normal)</li>
  <li>KNN (PCA)</li>
</ol>

<b>Female Accuracy</b>
<ol>
  <li>Random Forest</li>
  <li>KNN (PCA)</li>
  <li>Log Regression (Normal)</li>
</ol>

<b>AUC</b>
<ol>
  <li>Random Forest</li>
  <li>Log Regression</li>
  <li>Log Regression (Normal)</li>
</ol>

### <font size="5"><b>ROC</b></font>
```{r}
ggplotly(model_roc) %>%
  config(displayModeBar = F)
```

***
<font size="3"><b>Area Under the Curve</b></font><br>
<ul>
  <li>KNN: `r knn$auc$auc`</li>
  <li>Decision Tree: `r dt$auc$auc`</li>
  <li>SVM: `r svm$auc$auc`</li>
  <li>Log Reg: `r lr$auc$auc`</li>
  <li>KNN (PCA): `r knn.pca$auc$auc`</li>
  <li><b>Random Forest</b>: `r rf$auc$auc`</li>
  <li>SVM (PCA): `r svm.pca$auc$auc`</li>
  <li>Log Reg (Normal): `r lr.norm$auc$auc`</li>
</ul>

### <font size="5"><b>Fitting Times</b></font>
```{r}
ggplotly(fit_time.graph) %>%
  layout(showlegend = FALSE) %>% 
  config(displayModeBar = F)
```

### <font size="5"><b>Scoring Times</b></font>
```{r}
ggplotly(score_time.graph) %>%
  layout(showlegend = FALSE) %>% 
  config(displayModeBar = F)
```


### <font size="5"><b>Conclusion</b></font>
<font size="5"><b>Best Model</b></font>
<font size="3">
<ul>
  <li>Best Model: Random Forest</li>
  <li>2nd highest overall accuracy</li>
  <li>1st Female accuracy</li>
  <li>Highest Area Under the Curve</li>
  <li>Decent Fitting Time</li>
  <li>Faster Scoring Time</li>
</ul>
</font>
<font size="5"><b>Improvements</b></font>
<font size="3">
<ul>
  <li>Focus on a single method</li>
  <li>Combine features to create new ones</li>
  <li>Implement more advanced methods (Bagging/Boosting)</li>
  <li>Extract features from raw aaudio files</li>
</ul>
</font>
