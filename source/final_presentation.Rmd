---
title: "Voice Recognition"
output: 
  flexdashboard::flex_dashboard:
    orientation: columns
    vertical_layout: fill
    css: style.css
    theme: journal
---

```{r setup, include=FALSE}
library(flexdashboard)
source('_Packages.R')
source('_Data.R')
source('_EDA.R')
source('_ModelResults.R')
```

Home
=====================================

## Column
<center>
<h1><b>Gender Classification via Voice</b></h1>
<h3>Jake Whalen</h3>
<h5>CS 584 Final Project</h5>
<h5>Fall 2017</h5>
[Start](#summary)
</center>

Summary
=====================================
## Column
###
<center>
<font size="5"><b>Choosing a Project</b></font>
<br>
<font size="3">
Topic? Sports, Beer, Other <br>
Supervised or unsupervised learning?<br>
Data Source: Download, Web Scrape, Social Media<br>
Tools: Python, R, Weka, Tableau, Excel<br>
</font>
<br>
<font size="5"><b>Choice</b></font>
<br>
<font size="3">
Data from Kaggle<br>
Audio Analysis<br>
Supervised Learning<br>
Classification<br>
ML in Python<br>
Presentation & Report in R Markdown<br>
Excel for results transfer<br>
</font>
<br>
<font size="5"><b>Goals</b></font>
<br>
<font size="3">
Classify audio clip subjects gender<br>
Learn what audio features best seperate genders<br>
</font>
</center>

Method
=====================================

## Column

### <b>Exploration</b>
<ol>
  <li>Read data into R</li>
  <li>Ran summary functions on features</li>
  <li>Plot the data</li>
  <li>Look for patterns and relationships</li>
  <li>Determine what features seperate genders best</li>
</ol>

###
```{r}
ggplotly(scatterSample) %>%
  layout(showlegend = FALSE) %>% 
  config(displayModeBar = F)
```

## Column

### <b>Classification</b> {data-height=550}
<ol>
  <li>Used Scikit-learn in Python</li>
  <li>Split the data for training/testing (2/3, 1/3)</li>
  <li>Used gridsearch to identify the best parameters</li>
  <li>KNN (K-Nearest Neighbors)</li>
  <li>Decision Tree (DT)</li>
  <li>Suport Vector Machine (SVM)</li>
  <li>Logistic Regression (Log R)</li>
  <li>Observed classifications</li>
  <li>Attempt to improve on initial results</li>
  <li>KNN: Transform data with PCA</li>
  <li>Decision Tree: Use multiple trees with Random Forest</li>
  <li>SVM: Transform data with PCA</li>
  <li>Log R: Normalized data from 0 to 1 in each feature</li>
</ol>

###  {data-height=450}
<img src="C:/Users/e481340/Documents/GMU MASTERS/CS 584/CS584_Final/data/machine-learning.jpg" alt="Machine Learning">

## Column

### <b>Review</b>
<ul>
  <li>Confusion Matrix</li>
  <li>Overall Accuracy Scores</li>
  <li>Male Accuracy</li>
  <li>Female Accuracy</li>
  <li>ROC & AUC</li>
  <li>Parameter Influence</li>
  <li>Fit & Score Times</li>
</ul>

###
```{r}
ggplotly(knn_cm) %>%
  layout(showlegend = FALSE) %>% 
  config(displayModeBar = F)
```

Overview {data-navmenu="Data"}
=====================================

## Column {.tabset}

### Description
<font size="5"><b>Dataset Comments</b></font>
<font size="3">
<ul>
  <li>Database created to identify a voice as male or female, based upon acoustic properties of the voice and speech.</li>
  <li>The dataset consists of 3,168 recorded voice samples, collected from male and female speakers.</li>
  <li>The voice samples are pre-processed by acoustic analysis in R using the seewave and tuneR packages, with an analyzed frequency range of 0hz-280hz (human vocal range).</li>
  <li>The samples are represented by 21 different features</li>
  <li>Source: <a href="https://www.kaggle.com/primaryobjects/voicegender" target="_blank">Voice Gender Data</a></li>
</ul>
</font>

### Definitions
```{r definitionsTable}
definitions %>%
  datatable(., 
            rownames=F, 
            options = list(paging=F, 
                           dom = 't'))
```


### Sample

```{r sampleView}
voice %>%
  head(., n=20) %>%
  datatable(., 
            rownames=F, 
            options = list(paging=F, 
                           dom = 't'))
```

EDA {data-navmenu="Data"}
=====================================

## Column {.tabset}

### Classes
```{r}
genderCount
```

### Distributions

```{r Distributions}
allDensity
```

### Boxplots

```{r}
allBoxPlot
```

### Heatmap

```{r summary}
ggheatmap
```

### Scatter Plot

```{r Scatterplot}
oneVall
```

### 3D Plot

```{r 3D}
p
```

### T Test
```{r}
tTestDT
```


KNN {data-navmenu="Models"}
=====================================

## Column

<center><h4><b>K-Nearest Neighbors  [>>>](#decision-tree)</b></h4></center>

###
<b>Summary</b>
<ul>
  <li>Used untransformed data</li>
  <li>Better then a dumb classifier (50/50)</li>
  <li>Distance weights outperformed Uniform weights</li>
  <li><b>P:</b> Manhattan Distance produced better CV results (p=1)</li>
  <li><b>Algorithm:</b> auto attempts to decide the most appropriate algorithm based on values </li>
  <li><b>Weights:</b> distance weights points by the inverse of their distance. in this case, closer neighbors of a query point will have a greater influence than neighbors which are further away</li>
</ul>

<b>Best Parameters</b>
<ul>
  <li>`r best_params(knn)`</li>
</ul>

###
```{r}
ggplotly(knn_cm) %>%
  layout(showlegend = FALSE) %>% 
  config(displayModeBar = F)
```

## Column

###
```{r}
ggplotly(knn_score.graph) %>% 
  config(displayModeBar = F)
```

###
```{r}
knn_result_dt
```



Decision Tree {data-navmenu="Models"}
=====================================

## Column

<h4><b><center>Decision Tree  [>>>](#svm)</center></b></h4>

###
<b>Summary</b>
<ul>
  <li>Used untransformed data</li>
  <li>MeanFun, sp.ent & IQR account for +90% of feature importance</li>
  <li>Better at identifying males</li>
  <li>Easiest model to interpret (follow the branches)</li>
  <li><b>Presort:</b> presort the data to speed up the finding of best splits in fitting</li>
  <li><b>Splitter:</b> The strategy used to choose the split at each node</li>
  <li>[Tree](https://github.com/tjwhalenUVA/CS-584-Final/blob/master/Trees/dt.pdf)</li>
</ul>

<b>Best Parameters</b>
<ul>
  <li>`r best_params(dt)`</li>
</ul>



###
```{r}
ggplotly(dt_cm) %>%
  layout(showlegend = FALSE) %>% 
  config(displayModeBar = F)
```

## Column

###
```{r}
ggplotly(dt_feature.graph) %>%
  layout(showlegend = FALSE) %>% 
  config(displayModeBar = F)
```

###
```{r}
dt_result_dt
```

SVM {data-navmenu="Models"}
=====================================
## Column

<h4><b><center>Support Vector Machine  [>>>](#log-reg)</center></b></h4>

###
<b>Summary</b>
<ul>
  <li>Modified penalty parameter to achieve better results</li>
  <li>Higher penalties achieved better scores</li>
  <li>Better at classifying males</li>
</ul>

<b>Best Parameters</b>
<ul>
  <li>`r best_params(svm)`</li>
</ul>

###
```{r}
ggplotly(svm_cm) %>%
  layout(showlegend = FALSE) %>% 
  config(displayModeBar = F)
```

## Column

###
```{r}
ggplotly(svm_result.graph) %>%
  config(displayModeBar = F)
```

###
```{r}
svm_result_dt
```

Log Reg {data-navmenu="Models"}
=====================================
## Column

<h4><b><center>Logistic Regression  [>>>](#random-forest)</center></b></h4>

###
<b>Summary</b>
<ul>
  <li>Untransformed data</li>
  <li>Best Male accuracy</li>
  <li>Outperformed Log Reg (Normal)</li>
  <li><b>C:</b> Inverse of regularization strength</li>
  <li><b>fit_intercept:</b> Specifies if a constant (a.k.a. bias or intercept) should be added to the decision function</li>
  <li><b>penalty:</b> Used to specify the norm used in the penalization</li>
</ul>

<b>Best Parameters</b>
<ul>
  <li>`r best_params(lr)`</li>
</ul>

###
```{r}
ggplotly(lr_cm) %>%
  layout(showlegend = FALSE) %>% 
  config(displayModeBar = F)
```

## Column

###
```{r}
ggplotly(lr_result.graph) %>%
  layout(showlegend = FALSE) %>% 
  config(displayModeBar = F)
```

###
```{r}
lr_result_dt
```

Random Forest {data-navmenu="Models"}
=====================================

## Column

<h4><b><center>Random Forest  [>>>](#knn-pca)</center></b></h4>

###
<b>Summary</b>
<ul>
  <li>Best Female accuracy</li>
  <li>Took longer to fit then Decision Tree</li>
</ul>

<b>Best Parameters</b>
<ul>
  <li>`r best_params(rf)`</li>
</ul>

###
```{r}
ggplotly(rf_cm) %>%
  layout(showlegend = FALSE) %>% 
  config(displayModeBar = F)
```

## Column

###
```{r}
ggplotly(rf_result.graph) %>%
  layout(showlegend = FALSE) %>% 
  config(displayModeBar = F)
```

###
```{r}
rf_result_dt
```

KNN (PCA) {data-navmenu="Models"}
=====================================
## Column

<h4><b><center>K-Nearest Neighbors (PCA)  [>>>](#svm-pca)</center></b></h4>

###
<b>Summary</b>
<ul>
  <li>Best overall accuracy</li>
  <li>9 PCA components used</li>
  <li>The fewer the neighbors the better</li>
</ul>

<b>Best Parameters</b>
<ul>
  <li>`r best_params(knn.pca)`</li>
</ul>

###
```{r}
ggplotly(knn.pca_cm) %>%
  layout(showlegend = FALSE) %>% 
  config(displayModeBar = F)
```

## Column

###
```{r}
ggplotly(knn.pca_score.graph) %>%
  config(displayModeBar = F)
```

###
```{r}
knn.pca_result_dt
```

SVM (PCA) {data-navmenu="Models"}
=====================================
## Column

<h4><b><center>Support Vector Machine (PCA)  [>>>](#log-reg-normal)</center></b></h4>

###
<b>Summary</b>
<ul>
  <li>Improvement over SVM on untransformed data</li>
  <li>Adjusted penalty parameter C of the error term</li>
  <li>achieved best performance at much lower penalty parameter levels</li>
</ul>

<b>Best Parameters</b>
<ul>
  <li>`r best_params(svm.pca)`</li>
</ul>

###
```{r}
ggplotly(svm.pca_cm) %>%
  layout(showlegend = FALSE) %>% 
  config(displayModeBar = F)
```

## Column

###
```{r}
ggplotly(svm.pca_result.graph) %>%
  config(displayModeBar = F)
```

###
```{r}
svm.pca_result_dt
```

Log Reg (Normal) {data-navmenu="Models"}
=====================================
## Column

<h4><b><center>Logistic Regression (Normalized)  [>>>](#conclusions)</center></b></h4>

###
<b>Summary</b>
<ul>
  <li>Performed worse then Log Regression on untransformed data</li>
  <li>Decrease in performance due to decrease in Male accuracy</li>
  <li>Slight improvement in Female accuracy compared to first Log Reg</li>
</ul>

<b>Best Parameters</b>
<ul>
  <li>`r best_params(lr.norm)`</li>
</ul>

###
```{r}
ggplotly(lr.norm_cm) %>%
  layout(showlegend = FALSE) %>% 
  config(displayModeBar = F)
```

## Column

###
```{r}
ggplotly(lr.norm_result.graph) %>%
  layout(showlegend = FALSE) %>% 
  config(displayModeBar = F)
```

###
```{r}
lr.norm_result_dt
```


Conclusions {.storyboard}
=====================================

### <font size="5"><b>Criteria</b></font>
```{r}
ggplotly(model_criteria) %>%
  config(displayModeBar = F)
```

***
<b>Accuracy</b>
<ol>
  <li>KNN (PCA)</li>
  <li>Random Forest</li>
  <li>Log Regression</li>
</ol>

<b>Male Accuracy</b>
<ol>
  <li>Log Regression</li>
  <li>Log Regression (Normal)</li>
  <li>KNN (PCA)</li>
</ol>

<b>Female Accuracy</b>
<ol>
  <li>Random Forest</li>
  <li>KNN (PCA)</li>
  <li>Log Regression (Normal)</li>
</ol>

<b>AUC</b>
<ol>
  <li>Random Forest</li>
  <li>Log Regression</li>
  <li>Log Regression (Normal)</li>
</ol>

### <font size="5"><b>ROC</b></font>
```{r}
ggplotly(model_roc) %>%
  config(displayModeBar = F)
```

***
<font size="3"><b>Area Under the Curve</b></font><br>
<ul>
  <li>KNN: `r knn$auc$auc`</li>
  <li>Decision Tree: `r dt$auc$auc`</li>
  <li>SVM: `r svm$auc$auc`</li>
  <li>Log Reg: `r lr$auc$auc`</li>
  <li>KNN (PCA): `r knn.pca$auc$auc`</li>
  <li><b>Random Forest</b>: `r rf$auc$auc`</li>
  <li>SVM (PCA): `r svm.pca$auc$auc`</li>
  <li>Log Reg (Normal): `r lr.norm$auc$auc`</li>
</ul>

### <font size="5"><b>Fitting Times</b></font>
```{r}
ggplotly(fit_time.graph.pres) %>%
  layout(showlegend = FALSE) %>% 
  config(displayModeBar = F)
```

### <font size="5"><b>Scoring Times</b></font>
```{r}
ggplotly(score_time.graph.pres) %>%
  layout(showlegend = FALSE) %>% 
  config(displayModeBar = F)
```


### <font size="5"><b>Conclusion</b></font>
<center>
<font size="5"><b>Best Model</b></font>
<br>
<font size="3">
Best Model: Random Forest<br>
2nd highest overall accuracy<br>
1st Female accuracy<br>
Highest Area Under the Curve<br>
Decent Fitting Time<br>
Faster Scoring Time<br>
</font>
<font size="5"><b>Improvements</b></font>
<br>
<font size="3">
Focus on a single method<br>
Combine features to create new ones<br>
Implement more advanced methods (Bagging/Boosting)<br>
Extract features from raw aaudio files<br>
</font>
</center>
